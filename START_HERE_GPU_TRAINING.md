# ğŸš€ ì‹œì‘í•˜ê¸°: GPU ëª¨ë¸ í•™ìŠµ ì‹¤í–‰

**GLEC DTG EdgeAI - ë¡œì»¬ GPU í™˜ê²½ì—ì„œ ì‹¤ì œ ëª¨ë¸ í•™ìŠµ**

---

## âš¡ ë¹ ë¥¸ ì‹œì‘ (Windows)

### ì›í´ë¦­ ìë™í™” ì‹¤í–‰

```cmd
REM 1. Minicondaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
conda --version

REM 2. NVIDIA GPU í™•ì¸
nvidia-smi

REM 3. ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (ëª¨ë“  ê³¼ì • ìë™í™”)
quick_start_gpu.bat
```

**ì´ê²ƒë§Œ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤!** ìŠ¤í¬ë¦½íŠ¸ê°€ ìë™ìœ¼ë¡œ:
1. Conda í™˜ê²½ ìƒì„± (dtg-ai)
2. PyTorch + CUDA 11.8 ì„¤ì¹˜
3. ì˜ì¡´ì„± ì„¤ì¹˜ (requirements.txt)
4. ë°ì´í„°ì…‹ ìƒì„± (í…ŒìŠ¤íŠ¸ ë˜ëŠ” production)
5. TCN + LSTM-AE ëª¨ë¸ í•™ìŠµ (4-8ì‹œê°„)
6. ONNX ë³€í™˜ ë° Android í†µí•©

---

## ğŸ“‹ ìˆ˜ë™ ì‹¤í–‰ (ë‹¨ê³„ë³„)

ìë™í™” ìŠ¤í¬ë¦½íŠ¸ê°€ ì‘ë™í•˜ì§€ ì•Šê±°ë‚˜ ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš°:

### Step 1: í™˜ê²½ êµ¬ì¶• (30ë¶„-1ì‹œê°„)

```bash
# 1.1 Conda í™˜ê²½ ìƒì„±
conda create -n dtg-ai python=3.10 -y
conda activate dtg-ai

# 1.2 PyTorch + CUDA ì„¤ì¹˜
pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu118

# 1.3 ì˜ì¡´ì„± ì„¤ì¹˜
cd edgeai-repo
pip install -r requirements.txt

# 1.4 ê²€ì¦
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0)}')"
python -m pytest tests/ -v --tb=no -q --ignore=tests\e2e_test.py --ignore=tests\benchmark_inference.py
# ì˜ˆìƒ: 159/159 tests passing
```

---

### Step 2: ë°ì´í„° ìƒì„± (5-30ë¶„)

**ì˜µì…˜ A: í…ŒìŠ¤íŠ¸ ë°ì´í„° (ë¹ ë¥¸ ê²€ì¦, 5ë¶„)**
```bash
cd edgeai-repo
python ai-models/scripts/generate_test_dataset.py
# ê²°ê³¼: train.csv (800 samples), val.csv (150), test.csv (150)
```

**ì˜µì…˜ B: Production ë°ì´í„° (ì „ì²´ í•™ìŠµ, 30ë¶„)**
```bash
cd edgeai-repo
python ai-models/scripts/generate_production_dataset.py
# ê²°ê³¼: train.csv (8,000 samples), val.csv (1,500), test.csv (1,500)
```

**ê²€ì¦**:
```bash
python -c "import pandas as pd; df = pd.read_csv('datasets/train.csv'); print(f'Shape: {df.shape}'); print(f'Anomaly ratio: {(df.label != \"normal\").mean()*100:.1f}%')"
# ì˜ˆìƒ: Shape: (48000, 15), Anomaly ratio: 0.0%
```

---

### Step 3: TCN ëª¨ë¸ í•™ìŠµ (2-4ì‹œê°„)

```bash
cd edgeai-repo/ai-models/training
conda activate dtg-ai

# TCN í•™ìŠµ ì‹œì‘
python train_tcn.py --config ../config.yaml --epochs 100 --batch-size 64

# ì˜ˆìƒ ì¶œë ¥:
# Training on device: cuda
# Model parameters: 412928
# Epoch 1/100 | Train Loss: 0.3245 | Val Loss: 0.2891 | RÂ² Score: 0.6234 | Time: 45s
# ...
# Early stopping at epoch 42
# Training completed! Best validation loss: 0.1234
# Model saved: models/tcn_fuel_best.pth
```

**ëª¨ë‹ˆí„°ë§** (ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ):
```bash
watch -n 1 nvidia-smi  # Linux
# ë˜ëŠ” Windows: nvidia-smi (ìˆ˜ë™ìœ¼ë¡œ ë°˜ë³µ ì‹¤í–‰)

# ì˜ˆìƒ: GPU-Util 90-95%, Memory 8GB/12GB
```

**OOM ì—ëŸ¬ ë°œìƒ ì‹œ**:
```bash
# Batch size ì¤„ì´ê¸°
python train_tcn.py --config ../config.yaml --epochs 100 --batch-size 32
```

---

### Step 4: LSTM-AE ëª¨ë¸ í•™ìŠµ (2-4ì‹œê°„)

```bash
cd edgeai-repo/ai-models/training
conda activate dtg-ai

# LSTM-AE í•™ìŠµ ì‹œì‘
python train_lstm_ae.py --config ../config.yaml --epochs 100 --batch-size 64

# ì˜ˆìƒ ì¶œë ¥:
# Training on device: cuda
# Model parameters: 156672
# Calculating anomaly threshold... (from training data)
# Anomaly threshold: 0.0234
# Epoch 1/100 | Train Loss: 0.0456 | Val Loss: 0.0389 | F1: 0.6234 | Time: 52s
# ...
# Early stopping at epoch 38
# Training completed! Best F1 score: 0.8734
# Model saved: models/lstm_ae_best.pth
```

**ì¤‘ìš”**: LSTM-AEëŠ” ì •ìƒ ë°ì´í„°ë§Œ í•™ìŠµí•©ë‹ˆë‹¤!
- Training data: 0% anomaly (unsupervised learning)
- Validation data: 10% anomaly (threshold calibration)

---

### Step 5: ONNX ë³€í™˜ (10-20ë¶„)

```bash
cd edgeai-repo/ai-models/conversion
conda activate dtg-ai

# TCN ONNX ë³€í™˜
python -c "
import torch
import sys
sys.path.append('..')
from training.train_tcn import TCN

device = torch.device('cuda')
model = TCN(input_dim=11, output_dim=1, num_channels=[64, 128, 256]).to(device)
checkpoint = torch.load('../training/models/tcn_fuel_best.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

dummy_input = torch.randn(1, 60, 11).to(device)
torch.onnx.export(
    model, dummy_input, '../models/tcn_fuel_prediction.onnx',
    export_params=True, opset_version=13, do_constant_folding=True,
    input_names=['input'], output_names=['output']
)
print('âœ… TCN ONNX export complete')
"

# LSTM-AE ONNX ë³€í™˜
python -c "
import torch
import sys
sys.path.append('..')
from training.train_lstm_ae import LSTM_Autoencoder

device = torch.device('cuda')
model = LSTM_Autoencoder(input_dim=11, hidden_dim=128, num_layers=2, latent_dim=32).to(device)
checkpoint = torch.load('../training/models/lstm_ae_best.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

dummy_input = torch.randn(1, 60, 11).to(device)
torch.onnx.export(
    model, dummy_input, '../models/lstm_ae_anomaly_detection.onnx',
    export_params=True, opset_version=13, do_constant_folding=True
)
print('âœ… LSTM-AE ONNX export complete')
"

# ëª¨ë¸ í¬ê¸° í™•ì¸
dir ..\models\*.onnx  # Windows
# ë˜ëŠ”: ls -lh ../models/*.onnx  # Linux

# ì˜ˆìƒ:
# tcn_fuel_prediction.onnx           3.2 MB
# lstm_ae_anomaly_detection.onnx     2.1 MB
# Total: 5.3 MB (target: <14MB) âœ…
```

---

### Step 6: Android í†µí•© (30ë¶„-1ì‹œê°„)

```bash
# 6.1 ONNX ëª¨ë¸ì„ Android assetsë¡œ ë³µì‚¬
cd edgeai-repo

# Windows:
xcopy /Y ai-models\models\*.onnx android-dtg\app\src\main\assets\models\

# Linux:
cp ai-models/models/*.onnx android-dtg/app/src/main/assets/models/

# 6.2 Android APK ë¹Œë“œ
cd android-dtg

# Windows:
gradlew.bat assembleDebug

# Linux:
./gradlew assembleDebug

# ì˜ˆìƒ ì‹œê°„: 5-10ë¶„
# ê²°ê³¼: app\build\outputs\apk\debug\app-debug.apk

# 6.3 ë””ë°”ì´ìŠ¤ì— ì„¤ì¹˜
adb devices  # ë””ë°”ì´ìŠ¤ ì—°ê²° í™•ì¸
adb install -r app\build\outputs\apk\debug\app-debug.apk

# 6.4 ì•± ì‹¤í–‰ ë° ë¡œê·¸ í™•ì¸
adb shell am start -n com.glec.dtg/.MainActivity
adb logcat -s DTG:* EdgeAI:* ONNX:*

# ì˜ˆìƒ ë¡œê·¸:
# EdgeAI: TCN inference: 23.4ms âœ…
# EdgeAI: LSTM-AE inference: 31.2ms âœ…
# EdgeAI: LightGBM inference: 0.064ms âœ…
# EdgeAI: Total inference: 54.7ms (target: <50ms)
```

---

## âœ… ì„±ê³µ í™•ì¸

### ëª¨ë¸ ì„±ëŠ¥ ëª©í‘œ

| ëª¨ë¸ | í¬ê¸° ëª©í‘œ | ì§€ì—° ëª©í‘œ | ì •í™•ë„ ëª©í‘œ | ê²€ì¦ |
|------|----------|----------|------------|------|
| **TCN** | <4MB | <25ms | >85% RÂ² | `tcn_fuel_best.pth` ë‚´ `r2_score` |
| **LSTM-AE** | <3MB | <35ms | >85% F1 | `lstm_ae_best.pth` ë‚´ `f1_score` |
| **LightGBM** | <10MB | <15ms | >90% Acc | ì´ë¯¸ 99.54% âœ… |
| **Total** | <14MB | <50ms | - | í•©ê³„ í™•ì¸ |

### ê²€ì¦ ëª…ë ¹ì–´

```bash
cd edgeai-repo/ai-models/training

# TCN ì •í™•ë„ í™•ì¸
python -c "
import torch
checkpoint = torch.load('models/tcn_fuel_best.pth')
print(f'TCN RÂ² Score: {checkpoint[\"r2_score\"]:.4f} (target: >0.85)')
print(f'Status: {\"âœ… PASS\" if checkpoint[\"r2_score\"] > 0.85 else \"âŒ FAIL\"}')"

# LSTM-AE ì •í™•ë„ í™•ì¸
python -c "
import torch
checkpoint = torch.load('models/lstm_ae_best.pth')
print(f'LSTM-AE F1 Score: {checkpoint[\"f1_score\"]:.4f} (target: >0.85)')
print(f'Status: {\"âœ… PASS\" if checkpoint[\"f1_score\"] > 0.85 else \"âŒ FAIL\"}')"

# ëª¨ë¸ í¬ê¸° í™•ì¸
dir ..\models\*.onnx  # Windows
# ë˜ëŠ”: ls -lh ../models/*.onnx && du -sh ../models/*.onnx  # Linux
```

---

## ğŸ‰ ì™„ë£Œ!

**ì¶•í•˜í•©ë‹ˆë‹¤!** ë‹¤ìŒì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤:

1. âœ… GPU í™˜ê²½ êµ¬ì¶• (PyTorch + CUDA)
2. âœ… í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± (ë¬¼ë¦¬ ê¸°ë°˜ anomaly injection)
3. âœ… TCN ëª¨ë¸ í•™ìŠµ (ì—°ë£Œ ì†Œë¹„ ì˜ˆì¸¡)
4. âœ… LSTM-AE ëª¨ë¸ í•™ìŠµ (ì´ìƒ íƒì§€)
5. âœ… ONNX ë³€í™˜ (edge deployment)
6. âœ… Android í†µí•© (ì‹¤ ë””ë°”ì´ìŠ¤ í…ŒìŠ¤íŠ¸)

**ì´ ì†Œìš” ì‹œê°„**: 6-10ì‹œê°„
- í™˜ê²½ êµ¬ì¶•: 1ì‹œê°„
- ë°ì´í„° ìƒì„±: 30ë¶„
- ëª¨ë¸ í•™ìŠµ: 4-8ì‹œê°„
- ONNX ë³€í™˜ + Android: 1ì‹œê°„

---

## ğŸ“Š ë‹¤ìŒ ë‹¨ê³„

### ì„±ëŠ¥ ìµœì í™” (ì„ íƒ)

**INT8 Quantization** (ëª¨ë¸ í¬ê¸° 50-75% ê°ì†Œ):
```bash
cd edgeai-repo/ai-models/optimization

python quantize_models.py --model tcn --input ../models/tcn_fuel_prediction.onnx --output ../models/tcn_fuel_prediction_int8.onnx

python quantize_models.py --model lstm_ae --input ../models/lstm_ae_anomaly_detection.onnx --output ../models/lstm_ae_anomaly_detection_int8.onnx
```

---

### ì‹¤ì œ ì°¨ëŸ‰ í…ŒìŠ¤íŠ¸

1. STM32 CAN bus ì—°ê²°
2. ì‹¤ì œ ì°¨ëŸ‰ ë°ì´í„°ë¡œ ì¶”ë¡ 
3. Edge í™˜ê²½ ì„±ëŠ¥ ê²€ì¦
4. Fleet AI í”Œë«í¼ ì—°ë™

---

### í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ë” ë†’ì€ ì •í™•ë„)

```bash
# Grid search (ì˜ˆì‹œ)
for lr in 0.001 0.0005 0.0001; do
    python train_tcn.py --config ../config.yaml --epochs 200 --learning-rate $lr
done

# ë˜ëŠ” Optuna/Ray Tune ì‚¬ìš©
python hyperparameter_search.py --model tcn --trials 50
```

---

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ: CUDA out of memory

**í•´ê²°**:
```bash
# Batch size ì¤„ì´ê¸°
python train_tcn.py --batch-size 32  # 64 â†’ 32
python train_lstm_ae.py --batch-size 16  # 64 â†’ 16
```

---

### ë¬¸ì œ: í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼ (epochë‹¹ 5ë¶„ ì´ìƒ)

**í•´ê²°**:
```python
# train_tcn.py íŒŒì¼ ìˆ˜ì •
# Line ~320: DataLoader(..., num_workers=0) â†’ num_workers=4
```

---

### ë¬¸ì œ: ì •í™•ë„ê°€ ëª©í‘œì— ë¯¸ë‹¬

**í•´ê²°**:
```bash
# ë” ë§ì€ epoch
python train_tcn.py --epochs 200

# ë” ë§ì€ ë°ì´í„° (20,000 samples)
python ai-models/scripts/generate_production_dataset.py
# (ìŠ¤í¬ë¦½íŠ¸ ë‚´ num_samples ìˆ˜ì •)

# Learning rate ì¡°ì •
# config.yaml: learning_rate: 0.0005  # 0.001 â†’ 0.0005
```

---

### ë¬¸ì œ: Android APK ë¹Œë“œ ì‹¤íŒ¨

**í•´ê²°**:
```bash
# Gradle ìºì‹œ ì •ë¦¬
gradlew.bat clean
del /s /q .gradle
del /s /q build

# ë‹¤ì‹œ ë¹Œë“œ (ìƒì„¸ ë¡œê·¸)
gradlew.bat assembleDebug --stacktrace --info
```

---

## ğŸ“ ì¶”ê°€ ë¦¬ì†ŒìŠ¤

**ìƒì„¸ ê°€ì´ë“œ**:
1. **LOCAL_GPU_EXECUTION_GUIDE.md** - ì™„ì „í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œ (700+ lines)
2. **PRE_EXECUTION_VALIDATION_CHECKLIST.md** - 32ê°€ì§€ í™˜ê²½ ê²€ì¦ (1,220 lines)
3. **GPU_TRAINING_EXECUTION_GUIDE.md** - Phase-ë³„ ì‹¤í–‰ ê°€ì´ë“œ
4. **CURSOR.md** - Cursor AIë¥¼ ìœ„í•œ ê°€ì´ë“œ

**ìë™í™” ìŠ¤í¬ë¦½íŠ¸**:
- `quick_start_gpu.bat` - Windows ì›í´ë¦­ ì‹¤í–‰
- `ai-models/scripts/generate_test_dataset.py` - í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
- `ai-models/scripts/generate_production_dataset.py` - Production ë°ì´í„° ìƒì„±

**ë¬¸ì˜**:
- GitHub Issues: https://github.com/glecdev/edgeai/issues

---

## ğŸ“ í•µì‹¬ êµí›ˆ

### LSTM-AE Unsupervised Learning

**Critical**: LSTM-AutoencoderëŠ” **ì •ìƒ ë°ì´í„°ë§Œ** í•™ìŠµí•©ë‹ˆë‹¤!

```
Train:      0% anomaly   â†’ ëª¨ë¸ì´ ì •ìƒ íŒ¨í„´ í•™ìŠµ
Validation: 5-15% anomaly â†’ Threshold ë³´ì • (95th percentile)
Test:       5-15% anomaly â†’ ì„±ëŠ¥ í‰ê°€
```

**ì´ìœ **: AutoencoderëŠ” ì…ë ¥ì„ ì¬êµ¬ì„±í•˜ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤. ë§Œì•½ anomaly ë°ì´í„°ë¡œ í•™ìŠµí•˜ë©´, ëª¨ë¸ì€ anomalyë„ ì˜ ì¬êµ¬ì„±í•˜ê²Œ ë˜ì–´ anomaly detectionì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.

---

### Physics-Based Anomalies

**8ê°€ì§€ anomaly types** (Session 4ì—ì„œ êµ¬í˜„):
1. Overheating (ê³¼ì—´)
2. Overrevving (ê³¼ì†íšŒì „)
3. Harsh Braking (ê¸‰ì œë™)
4. Aggressive Acceleration (ê¸‰ê°€ì†)
5. Erratic Driving (ë¶ˆê·œì¹™ ìš´ì „)
6. Fuel Leak (ì—°ë£Œ ëˆ„ì¶œ)
7. Excessive Idling (ê³¼ë„í•œ ê³µíšŒì „)
8. GPS Jump (GPS ì˜¤ë¥˜)

**íŠ¹ì§•**:
- 3-phase temporal model (onset â†’ sustain â†’ recovery)
- Multi-feature correlations (acceleration â†” braking, RPM â†” throttle)
- Realistic commercial vehicle dynamics

---

### Hardware Estimates

| GPU | VRAM | ì˜ˆìƒ í•™ìŠµ ì‹œê°„ |
|-----|------|---------------|
| **RTX 4090** | 24GB | 3-4 hours âš¡ |
| **RTX 3080** | 10GB | 4-6 hours âœ… |
| **RTX 3060** | 12GB | 6-8 hours âœ… |
| **GTX 1660** | 6GB | 10-12 hours âš ï¸ |
| **CPU Only** | N/A | 4-6 days âŒ |

---

**ì¤€ë¹„ëë‚˜ìš”? ì‹œì‘í•˜ì„¸ìš”! ğŸš€**

```bash
# Windows: ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
quick_start_gpu.bat

# ë˜ëŠ” ìˆ˜ë™: Step 1ë¶€í„° ì‹œì‘
conda create -n dtg-ai python=3.10 -y
conda activate dtg-ai
...
```

**ì¢‹ì€ í•™ìŠµ ë˜ì„¸ìš”! ğŸ’ª**
